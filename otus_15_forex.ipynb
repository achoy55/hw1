{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 13:01:06.763059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736150466.797276   10624 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736150466.807423   10624 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 13:01:06.839997: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfinance version: 0.2.50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import import_ipynb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import talib as ta\n",
    "\n",
    "from redis_cli import RedisClient\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from file_loader import get_data, store_to_file\n",
    "from features import FeatureEngineering\n",
    "import utils as ut\n",
    "from data_loader import load_forex_data, load_forex_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = RedisClient(db=1, username='usr_redis', password='usr_pwd')\n",
    "# r.test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=-(datetime.now() - datetime(2016, 1, 1)).days\n",
    "time_interval='1d'\n",
    "tickers = ['EURUSD=X', 'GBPUSD=X', 'USDCHF=X', 'USDJPY=X']\n",
    "forex_tickers = ['EURUSD', 'GBPUSD', 'USDCHF', 'USDJPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start load forex data, tickers ['EURUSD=X', 'GBPUSD=X', 'USDCHF=X', 'USDJPY=X'], interval: 1d, from: 2016-01-01 13:01:09.727893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2348 entries, 2016-01-01 to 2025-01-06\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   (GBPUSD=X, Open)       2348 non-null   float64\n",
      " 1   (GBPUSD=X, High)       2348 non-null   float64\n",
      " 2   (GBPUSD=X, Low)        2348 non-null   float64\n",
      " 3   (GBPUSD=X, Close)      2348 non-null   float64\n",
      " 4   (GBPUSD=X, Adj Close)  2348 non-null   float64\n",
      " 5   (GBPUSD=X, Volume)     2348 non-null   int64  \n",
      " 6   (USDCHF=X, Open)       2348 non-null   float64\n",
      " 7   (USDCHF=X, High)       2348 non-null   float64\n",
      " 8   (USDCHF=X, Low)        2348 non-null   float64\n",
      " 9   (USDCHF=X, Close)      2348 non-null   float64\n",
      " 10  (USDCHF=X, Adj Close)  2348 non-null   float64\n",
      " 11  (USDCHF=X, Volume)     2348 non-null   int64  \n",
      " 12  (USDJPY=X, Open)       2348 non-null   float64\n",
      " 13  (USDJPY=X, High)       2348 non-null   float64\n",
      " 14  (USDJPY=X, Low)        2348 non-null   float64\n",
      " 15  (USDJPY=X, Close)      2348 non-null   float64\n",
      " 16  (USDJPY=X, Adj Close)  2348 non-null   float64\n",
      " 17  (USDJPY=X, Volume)     2348 non-null   int64  \n",
      " 18  (EURUSD=X, Open)       2348 non-null   float64\n",
      " 19  (EURUSD=X, High)       2348 non-null   float64\n",
      " 20  (EURUSD=X, Low)        2348 non-null   float64\n",
      " 21  (EURUSD=X, Close)      2348 non-null   float64\n",
      " 22  (EURUSD=X, Adj Close)  2348 non-null   float64\n",
      " 23  (EURUSD=X, Volume)     2348 non-null   int64  \n",
      "dtypes: float64(20), int64(4)\n",
      "memory usage: 458.6 KB\n",
      "Download forex data completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = load_forex_data(tickers, period, time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_and_plot(data, column_name1, column_name2):\n",
    "    df = data.copy()\n",
    "    X_train = df[column_name1]\n",
    "    y_train = df[column_name2]\n",
    "\n",
    "    # without normalization\n",
    "    model_no_norm = ut.linear_regression(X_train, y_train)\n",
    "    weights_no_norm = model_no_norm.coef_\n",
    "\n",
    "    # normalize data\n",
    "    prices_norm, volume_norm = ut.normalize_MinMax_by_column(X_train, y_train)\n",
    "    # print(prices_norm)\n",
    "\n",
    "    model_with_norm = ut.linear_regression(prices_norm, volume_norm)\n",
    "    weights_with_norm = model_with_norm.coef_\n",
    "\n",
    "    # Plotting the weights\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    axes[0].bar(['Price', 'Volume'], weights_no_norm, color='red')\n",
    "    axes[0].set_title('Weigth without normalization')\n",
    "    axes[0].set_ylabel('Model weghts')\n",
    "\n",
    "    axes[1].bar(['Price', 'Volume'], weights_with_norm, color='green')\n",
    "    axes[1].set_title('Weigth after normalization')\n",
    "    axes[1].set_ylabel('Model weghts')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_type = file, redis\n",
    "def merge_and_store_data(new_df, key, store_type='file', compress=False):\n",
    "    if store_type == 'redis':\n",
    "        saved_data = r.get_key(key)\n",
    "    else:\n",
    "        saved_data = get_data('_data_store', key, compress=compress)\n",
    "\n",
    "    merged_df = ut.validate_duplicate_and_merge(saved_data, new_df)\n",
    "\n",
    "    if store_type == 'redis':\n",
    "        r.set_key(key, merged_df)\n",
    "    else:\n",
    "        store_to_file(merged_df, key, compress=compress)\n",
    "\n",
    "    merged_df.dropna(inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, n_splits, X, y, date_col = None):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (11, 7))\n",
    "    \n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=10, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits))\n",
    "    \n",
    "    if date_col is not None:\n",
    "        tick_locations  = ax.get_xticks()\n",
    "        tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-1])].astype(str).tolist() + [\" \"]\n",
    "\n",
    "        tick_locations_str = [str(int(i)) for i in tick_locations]\n",
    "        new_labels = ['\\n\\n'.join(x) for x in zip(list(tick_locations_str), tick_dates) ]\n",
    "        ax.set_xticks(tick_locations)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    \n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+0.2, -.2])\n",
    "    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importance(model, model_func, params):\n",
    "    importance_function = model.coef_[0]\n",
    "    if model_func in [ut.ModelFunc.XGBOOST_CLASS, ut.ModelFunc.DECISION_TREE_CLASS, ut.ModelFunc.RANDOM_FOREST_CLASS, \\\n",
    "                      ut.ModelFunc.KNN_CLASS, ]:\n",
    "        importance_function = model.feature_importances_\n",
    "    if model_func in [ut.ModelFunc.CATBOOST_CLASS, ]:\n",
    "        importance_function = model.get_feature_importance()\n",
    "\n",
    "    ut.top_n_weighted_factors(importance_function, params['features'], params['top'])\n",
    "    return importance_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Blending, Stacking, Ensemble\n",
    "def fit_models(model_funcs, X_train, y_train, X_val=None, y_val=None):\n",
    "    models = list()\n",
    "    for model_func in model_funcs:\n",
    "        params = ut.get_model_params(model_func)\n",
    "        if X_val is None or y_val is None:\n",
    "            model = ut.model_fit(model_func, X_train, y_train, params)\n",
    "        else:\n",
    "            if model_func is ut.ModelFunc.CATBOOST_CLASS:\n",
    "                params = dict(params, early_stopping_rounds=50)\n",
    "                model = ut.model_fit_with_eval(model_func, X_train, y_train, eval_set=(X_val, y_val), params=params)\n",
    "            else:\n",
    "                model = ut.model_fit(model_func, X_train, y_train, params)\n",
    "        models.append(model)\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_models(models, X_train, X_val, X_test):\n",
    "    models_proba = list()\n",
    "    for model in models:\n",
    "        models_proba.append({\n",
    "            'train': np.array(model.predict_proba(X_train)[:, 1]),\n",
    "            'val': np.array(model.predict_proba(X_val)[:, 1]),\n",
    "            'test': np.array(model.predict_proba(X_test)[:, 1])\n",
    "        })\n",
    "\n",
    "    return models_proba\n",
    "\n",
    "\n",
    "def blending_pred(*args):\n",
    "    return sum(args) / len(args)\n",
    "    \n",
    "def stacking_pred(*args):\n",
    "    return np.column_stack(args)\n",
    "\n",
    "# stacking_pred(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'emaf': 20,\n",
    "    'emam': 100,\n",
    "    'emas': 150,\n",
    "    'rsi': 14,\n",
    "    'macd': [12, 26, 9],\n",
    "    'max_train_size': 90,\n",
    "    'test_size': 30\n",
    "}\n",
    "\n",
    "trend_indicators = [ 'emaf', 'emam', 'emas', 'rsi', 'macd', 'adx']\n",
    "lag_periods = 7 #3 # depends on timeframe, 7 days - ???\n",
    "min_outliers=.23\n",
    "max_outliers=.77\n",
    "threshold = 0.6 # ???\n",
    "use_stacking = True\n",
    "use_blending = False\n",
    "\n",
    "fe = FeatureEngineering(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(model_funcs, data_with_features, features):\n",
    "    for train_data, val_data, test_data in tqdm(fe.split_data(data_with_features)):\n",
    "        X_train, y_train = train_data[features], train_data['Target']\n",
    "        X_val, y_val     = val_data[features], val_data['Target']\n",
    "        X_test, y_test   = test_data[features], test_data['Target']\n",
    "\n",
    "        ## Data normalization\n",
    "        # X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_MinMaxScaler(X_train, X_val, X_test)\n",
    "        X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_StandardScaler(X_train, X_val, X_test)\n",
    "    \n",
    "        ## Modeling\n",
    "        # models = models_fit(model_funcs, X_train_scaled, y_train, X_val=X_val, y_val=y_val)\n",
    "        models = fit_models(model_funcs, X_train_scaled, y_train)\n",
    "\n",
    "        ## Prediction on train, val and test samples\n",
    "        predict_dict = predict_models(models, X_train_scaled, X_val_scaled, X_test_scaled)\n",
    "\n",
    "        yield ( predict_dict, y_train, y_val, y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = list()\n",
    "    # models.append(ut.ModelFunc.LOGISTIC_REG)\n",
    "    # models.append(ut.ModelFunc.LINEAR_REG)\n",
    "    # models.append(ut.ModelFunc.KNN_REG)\n",
    "    # models.append(ut.ModelFunc.DECISION_TREE_REG)\n",
    "    # models.append(ut.ModelFunc.RANDOM_FOREST_REG)\n",
    "    # models.append(ut.ModelFunc.CATBOOST_REG)\n",
    "    # models.append(ut.ModelFunc.XGBOOST_REG)\n",
    "\n",
    "    # models.append(ut.ModelFunc.XGBOOST_CLASS)\n",
    "    # models.append(ut.ModelFunc.CATBOOST_CLASS)\n",
    "\n",
    "    # models.append(ut.ModelFunc.RANDOM_FOREST_CLASS)\n",
    "    models.append(ut.ModelFunc.DECISION_TREE_CLASS)\n",
    "    models.append(ut.ModelFunc.KNN_CLASS)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== symbol: EURUSD, stacking: True, blending: False ===\n",
      "Outliers detected: 0\n",
      "            Date      Open      High       Low     Close  Volume       rsi  \\\n",
      "2331  2024-12-12  1.050685  1.052997  1.046485  1.050685       0  0.796998   \n",
      "2332  2024-12-13  1.047406  1.052299  1.045435  1.047406       0  0.740678   \n",
      "2333  2024-12-16  1.051005  1.052410  1.047504  1.051005       0  0.839565   \n",
      "2334  2024-12-17  1.051735  1.053286  1.047998  1.051735       0  0.859156   \n",
      "2335  2024-12-18  1.049505  1.051525  1.046781  1.049505       0  0.814779   \n",
      "2336  2024-12-19  1.035025  1.042220  1.035250  1.035025       0  0.598561   \n",
      "2337  2024-12-20  1.036495  1.043308  1.034426  1.036495       0  0.638727   \n",
      "2338  2024-12-23  1.043308  1.044823  1.038594  1.043308       0  0.809543   \n",
      "2339  2024-12-24  1.040583  1.041124  1.038745  1.040583       0  0.768695   \n",
      "2340  2024-12-25  1.040258  1.043297  1.040150  1.040258       0  0.763750   \n",
      "\n",
      "          emaf      emam      emas  ...  Low_ratio_1  Low_log_diff_1  \\\n",
      "2331  0.943182  0.961709  0.963901  ...     0.998399       -0.001602   \n",
      "2332  0.942387  0.961163  0.963502  ...     0.998996       -0.001004   \n",
      "2333  0.941975  0.960692  0.963151  ...     1.001980        0.001978   \n",
      "2334  0.941663  0.960244  0.962813  ...     1.000472        0.000471   \n",
      "2335  0.941192  0.959764  0.962453  ...     0.998838       -0.001163   \n",
      "2336  0.939535  0.959039  0.961927  ...     0.988985       -0.011076   \n",
      "2337  0.938160  0.958354  0.961425  ...     0.999204       -0.000797   \n",
      "2338  0.937496  0.957802  0.961010  ...     1.004030        0.004022   \n",
      "2339  0.936663  0.957214  0.960569  ...     1.000145        0.000145   \n",
      "2340  0.935882  0.956631  0.960129  ...     1.001352        0.001351   \n",
      "\n",
      "      Low_momentum_7  Low_roc_7  Low_ema_7  Close_ratio_1  Close_log_diff_1  \\\n",
      "2331       -0.001700  -0.162212   1.049257       0.997520         -0.002483   \n",
      "2332       -0.001960  -0.187135   1.048301       0.996879         -0.003126   \n",
      "2333       -0.003391  -0.322635   1.048102       1.003437          0.003431   \n",
      "2334       -0.006609  -0.626698   1.048076       1.000694          0.000694   \n",
      "2335       -0.006527  -0.619696   1.047752       0.997880         -0.002122   \n",
      "2336       -0.014784  -1.407930   1.044627       0.986203         -0.013893   \n",
      "2337       -0.013737  -1.310609   1.042076       1.001420          0.001419   \n",
      "2338       -0.007891  -0.754020   1.041206       1.006573          0.006551   \n",
      "2339       -0.006689  -0.639871   1.040591       0.997388         -0.002615   \n",
      "2340       -0.007354  -0.702097   1.040480       0.999688         -0.000312   \n",
      "\n",
      "      Close_momentum_7  Close_roc_7  Close_ema_7  \n",
      "2331          0.000563     0.053581     1.053437  \n",
      "2332         -0.003677    -0.349831     1.051929  \n",
      "2333         -0.000409    -0.038889     1.051698  \n",
      "2334         -0.006825    -0.644719     1.051707  \n",
      "2335         -0.007041    -0.666437     1.051157  \n",
      "2336         -0.020495    -1.941713     1.047124  \n",
      "2337         -0.016802    -1.595166     1.044467  \n",
      "2338         -0.007377    -0.702150     1.044177  \n",
      "2339         -0.006823    -0.651414     1.043278  \n",
      "2340         -0.010747    -1.022575     1.042523  \n",
      "\n",
      "[10 rows x 35 columns]\n",
      "            Date      Open      High       Low     Close  Volume       rsi  \\\n",
      "2331  2024-12-12  1.050685  1.052997  1.046485  1.050685       0  0.796998   \n",
      "2332  2024-12-13  1.047406  1.052299  1.045435  1.047406       0  0.740678   \n",
      "2333  2024-12-16  1.051005  1.052410  1.047504  1.051005       0  0.839565   \n",
      "2334  2024-12-17  1.051735  1.053286  1.047998  1.051735       0  0.859156   \n",
      "2335  2024-12-18  1.049505  1.051525  1.046781  1.049505       0  0.814779   \n",
      "2336  2024-12-19  1.035025  1.042220  1.035250  1.035025       0  0.598561   \n",
      "2337  2024-12-20  1.036495  1.043308  1.034426  1.036495       0  0.638727   \n",
      "2338  2024-12-23  1.043308  1.044823  1.038594  1.043308       0  0.809543   \n",
      "2339  2024-12-24  1.040583  1.041124  1.038745  1.040583       0  0.768695   \n",
      "2340  2024-12-25  1.040258  1.043297  1.040150  1.040258       0  0.763750   \n",
      "\n",
      "          emaf      emam      emas  ...  Low_ratio_1  Low_log_diff_1  \\\n",
      "2331  0.943182  0.961709  0.963901  ...     0.998399       -0.001602   \n",
      "2332  0.942387  0.961163  0.963502  ...     0.998996       -0.001004   \n",
      "2333  0.941975  0.960692  0.963151  ...     1.001980        0.001978   \n",
      "2334  0.941663  0.960244  0.962813  ...     1.000472        0.000471   \n",
      "2335  0.941192  0.959764  0.962453  ...     0.998838       -0.001163   \n",
      "2336  0.939535  0.959039  0.961927  ...     0.988985       -0.011076   \n",
      "2337  0.938160  0.958354  0.961425  ...     0.999204       -0.000797   \n",
      "2338  0.937496  0.957802  0.961010  ...     1.004030        0.004022   \n",
      "2339  0.936663  0.957214  0.960569  ...     1.000145        0.000145   \n",
      "2340  0.935882  0.956631  0.960129  ...     1.001352        0.001351   \n",
      "\n",
      "      Low_momentum_7  Low_roc_7  Low_ema_7  Close_ratio_1  Close_log_diff_1  \\\n",
      "2331       -0.001700  -0.162212   1.049257       0.997520         -0.002483   \n",
      "2332       -0.001960  -0.187135   1.048301       0.996879         -0.003126   \n",
      "2333       -0.003391  -0.322635   1.048102       1.003437          0.003431   \n",
      "2334       -0.006609  -0.626698   1.048076       1.000694          0.000694   \n",
      "2335       -0.006527  -0.619696   1.047752       0.997880         -0.002122   \n",
      "2336       -0.014784  -1.407930   1.044627       0.986203         -0.013893   \n",
      "2337       -0.013737  -1.310609   1.042076       1.001420          0.001419   \n",
      "2338       -0.007891  -0.754020   1.041206       1.006573          0.006551   \n",
      "2339       -0.006689  -0.639871   1.040591       0.997388         -0.002615   \n",
      "2340       -0.007354  -0.702097   1.040480       0.999688         -0.000312   \n",
      "\n",
      "      Close_momentum_7  Close_roc_7  Close_ema_7  \n",
      "2331          0.000563     0.053581     1.053437  \n",
      "2332         -0.003677    -0.349831     1.051929  \n",
      "2333         -0.000409    -0.038889     1.051698  \n",
      "2334         -0.006825    -0.644719     1.051707  \n",
      "2335         -0.007041    -0.666437     1.051157  \n",
      "2336         -0.020495    -1.941713     1.047124  \n",
      "2337         -0.016802    -1.595166     1.044467  \n",
      "2338         -0.007377    -0.702150     1.044177  \n",
      "2339         -0.006823    -0.651414     1.043278  \n",
      "2340         -0.010747    -1.022575     1.042523  \n",
      "\n",
      "[10 rows x 35 columns]\n",
      "Models: [<function decision_tree_classifier_model at 0x7f03ad119c60>, <function knn_classifier_model at 0x7f03ad119da0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:01, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train sample metrics ===\n",
      "ROC AUC: 1.0000\n",
      "   Cutoff  Precision  Recall  Accuracy  F1-Score\n",
      "0    50.0      100.0   100.0     100.0     100.0\n",
      "1    60.0      100.0   100.0     100.0     100.0\n",
      "2    70.0      100.0   100.0     100.0     100.0\n",
      "3    80.0      100.0   100.0     100.0     100.0\n",
      "=== Val sample metrics ===\n",
      "ROC AUC: 1.0000\n",
      "   Cutoff  Precision  Recall  Accuracy  F1-Score\n",
      "0    50.0      100.0   100.0     100.0     100.0\n",
      "1    60.0      100.0   100.0     100.0     100.0\n",
      "2    70.0      100.0   100.0     100.0     100.0\n",
      "3    80.0      100.0   100.0     100.0     100.0\n",
      "=== Test sample metrics ===\n",
      "ROC AUC: 1.0000\n",
      "   Cutoff  Precision  Recall  Accuracy  F1-Score\n",
      "0    50.0      100.0   100.0     100.0     100.0\n",
      "1    60.0      100.0   100.0     100.0     100.0\n",
      "2    70.0      100.0   100.0     100.0     100.0\n",
      "3    80.0      100.0   100.0     100.0     100.0\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "symbols =['EURUSD']\n",
    "for symbol in symbols:\n",
    "# for name in tqdm(tickers):\n",
    "    print(f'=== symbol: {symbol}, stacking: {use_stacking}, blending: {use_blending} ===')\n",
    "\n",
    "    data = get_data(data_dir, symbol)\n",
    "    data.drop(columns=['chg', 'vol_chg'], inplace=True) # Could it be as features ?\n",
    "\n",
    "    df = fe.clear_invalid_targets(fe.add_target(fe.enrich_with_indicators(data), lag_periods))\n",
    "    # df = fe.clear_invalid_targets(fe.add_target2(fe.enrich_with_indicators(data)))\n",
    "    df = fe.validate_outliers(df, 'Close', min_outliers, max_outliers)\n",
    "    # # print(df.isnull().sum())\n",
    "    \n",
    "    ## Store data\n",
    "    # df = merge_and_store_data(df, symbol, compress=True) # Store data\n",
    "    # print(df.isnull().sum())\n",
    "\n",
    "    ## Add features\n",
    "    OHLCV = ['Open', 'High', 'Low', 'Close']\n",
    "\n",
    "    # Trend features\n",
    "    data_with_trend, new_trend_features = fe.create_trend_features(df, OHLCV, lag_periods)\n",
    "    # print(data_with_trend.isnull().sum())\n",
    "    features = new_trend_features + trend_indicators  + ['Target']\n",
    "    data_with_features = data_with_trend[features + ['Date']]\n",
    "\n",
    "\n",
    "    # Rolling features\n",
    "    # window_sizes = [7, 14, 30]\n",
    "    # data_with_rolling, new_rolling_features = fe.create_rolling_features(df, OHLCV, window_sizes)\n",
    "    # features = new_rolling_features + trend_indicators + ['Target']\n",
    "    # data_with_features = data_with_rolling[features + ['Date']]\n",
    "\n",
    "    # print(len(data_with_features))\n",
    "    # print(data_with_features.isnull().sum())\n",
    "    data_with_features.set_index('Date', inplace=True)\n",
    "    # display(data_with_features.tail(10))\n",
    "\n",
    "\n",
    "    model_funcs = get_models()\n",
    "    print(f'Models: {model_funcs}')\n",
    "\n",
    "    ## Split, predict\n",
    "    train_pred_prob = list()\n",
    "    val_pred_prob = list()\n",
    "    test_pred_prob = list()\n",
    "    y_train_total = pd.DataFrame()\n",
    "    y_val_total = pd.DataFrame()\n",
    "    y_test_total = pd.DataFrame()\n",
    "\n",
    "    for predict_dict, y_train, y_val, y_test in predict_ensemble(model_funcs, data_with_features, features):\n",
    "        y_train_total = pd.concat([y_train_total, y_train])\n",
    "        y_val_total = pd.concat([y_val_total, y_val])\n",
    "        y_test_total = pd.concat([y_test_total, y_test])\n",
    "\n",
    "        train_pred_prob.append([d['train'] for d in predict_dict][0])\n",
    "        val_pred_prob.append([d['val'] for d in predict_dict][0])\n",
    "        test_pred_prob.append([d['test'] for d in predict_dict][0])\n",
    "\n",
    "    ## 2D-array\n",
    "    train_pred_prob = hstack(train_pred_prob)\n",
    "    val_pred_prob = hstack(val_pred_prob)\n",
    "    test_pred_prob = hstack(test_pred_prob)\n",
    "\n",
    "\n",
    "    ## Final model using whole data\n",
    "    if use_stacking:\n",
    "        stacked_train_X = stacking_pred(train_pred_prob).reshape(-1,1)\n",
    "        stacked_val_X = stacking_pred(val_pred_prob).reshape(-1,1)\n",
    "        stacked_test_X = stacking_pred(test_pred_prob).reshape(-1,1)\n",
    "        \n",
    "        final_model_func = ut.ModelFunc.LOGISTIC_REG \n",
    "        final_model = fit_models([final_model_func], stacked_train_X, y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], stacked_train_X, stacked_val_X, stacked_test_X)\n",
    "\n",
    "    elif use_blending:\n",
    "        blended_train_X = stacking_pred(train_pred_prob).reshape(-1,1)\n",
    "        blended_val_X = stacking_pred(val_pred_prob).reshape(-1,1)\n",
    "        blended_test_X = stacking_pred(test_pred_prob).reshape(-1,1)\n",
    "\n",
    "        final_model_func = ut.ModelFunc.LOGISTIC_REG\n",
    "        final_model = fit_models([final_model_func], blended_train_X, y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], blended_train_X, blended_val_X, blended_test_X)\n",
    "\n",
    "    else:\n",
    "        final_model_func = model_funcs[0]\n",
    "        final_model = fit_models([final_model_func], train_pred_prob.reshape(-1,1), y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], train_pred_prob.reshape(-1,1), val_pred_prob.reshape(-1,1),\\\n",
    "                                       test_pred_prob.reshape(-1,1))\n",
    "\n",
    "        # params = {\n",
    "        #     'features': features,\n",
    "        #     'top': 5,\n",
    "        # }\n",
    "        # importance_features = show_importance(final_model, final_model_func, params)\n",
    "\n",
    "    ensemble_train = [d['train'] for d in predict_dict][0]\n",
    "    ensemble_val = [d['val'] for d in predict_dict][0]\n",
    "    ensemble_test = [d['test'] for d in predict_dict][0]\n",
    "\n",
    "    # ## Display metrics, ROC AUC for train, val and test samples\n",
    "    train_roc_auc = ut.roc_auc_score_metric(y_train_total, ensemble_train)\n",
    "    val_roc_auc = ut.roc_auc_score_metric(y_val_total, ensemble_val)\n",
    "    test_roc_auc = ut.roc_auc_score_metric(y_test_total, ensemble_test)\n",
    "  \n",
    "    print('=== Train sample metrics ===')\n",
    "    print(f'ROC AUC: {train_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_train_total, ensemble_train))\n",
    "\n",
    "    print('=== Val sample metrics ===')\n",
    "    print(f'ROC AUC: {val_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_val_total, ensemble_val))\n",
    "\n",
    "    print('=== Test sample metrics ===')\n",
    "    print(f'ROC AUC: {test_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_test_total, ensemble_test))\n",
    "    print('===========================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
