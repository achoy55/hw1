{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from tzlocal import get_localzone\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import train_model as tm\n",
    "import data_processing as dp\n",
    "from data_loader import load_data_at_start_date, load_data_period\n",
    "from features import FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_params = {\n",
    "    'emaf': 20,\n",
    "    'emam': 100,\n",
    "    'emas': 150,\n",
    "    'rsi': 14,\n",
    "    'macd': [12, 26, 9],\n",
    " }\n",
    "\n",
    "fe = FeatureEngineering(fe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params):   \n",
    "    data_store = params['data_store_dir']\n",
    "    file_compress = params['file_compress']\n",
    "    tickers = params['tickers']\n",
    "    trend_features = params['trend_features']\n",
    "    \n",
    "    for ticker in tqdm(tickers):\n",
    "        data_with_trend = dp.get_data(data_store, ticker, compress=file_compress) ## Data contains features and TA indicators\n",
    "        print(f'Train data length: {len(data_with_trend)}')\n",
    "        # print(data_with_trend.isnull().sum())\n",
    "        # print(data_with_trend.tail(5))\n",
    "\n",
    "        features = [d[ticker] for d in trend_features if ticker in d.keys()][0] + params['trend_indicators']\n",
    "        data_with_features = data_with_trend[features + params['target_columns']]\n",
    "\n",
    "        params['features'] = features\n",
    "        tm.predict_process(data_with_features, params)\n",
    "\n",
    "    print(f'=== Finish Train models ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_data(data, params):\n",
    "    features = params['OHLCV']\n",
    "    lag_periods = params['lag_periods']\n",
    "    min_outliers=params['min_outliers']\n",
    "    max_outliers=params['max_outliers']\n",
    "\n",
    "    df = fe.clear_invalid_targets(fe.add_target(fe.enrich_with_indicators(data), lag_periods))\n",
    "    # df = fe.clear_invalid_targets(fe.add_target2(fe.enrich_with_indicators(data)))\n",
    "    df = fe.validate_outliers(df, 'Close', min_outliers, max_outliers)\n",
    "    # # print(df.isnull().sum())\n",
    "    \n",
    "    return fe.create_trend_features(df, features, lag_periods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(params):\n",
    "    print('=== Start feature generation ===')\n",
    "    \n",
    "    tickers = params['tickers']\n",
    "    data_store = params['data_store_dir']\n",
    "    new_data_dir = params['new_data_dir']\n",
    "    file_compress = params['file_compress']\n",
    "\n",
    "    trend_features = list()\n",
    "    for ticker in tqdm(tickers):\n",
    "        print(f'=== Add feature, ticker: {ticker} ===')\n",
    "\n",
    "        new_df = dp.get_data(new_data_dir, ticker, compress=False) # get new raw data\n",
    "        new_df.dropna(inplace=True)\n",
    "\n",
    "        data_with_trend, new_trend_features = get_trend_data(new_df, params)\n",
    "        # print(data_with_trend.isnull().sum())\n",
    "        # print(data_with_trend.tail(5))\n",
    "        dp.merge_and_store_new_data(data_with_trend, ticker, data_store, compress=file_compress) # merge with before saved and validate duplication data\n",
    "        \n",
    "        trend_features.append({\n",
    "            ticker: new_trend_features\n",
    "        })\n",
    "\n",
    "        ## Plot\n",
    "        if params['is_plot']:\n",
    "            dp.plot_data(data_with_trend)\n",
    "            \n",
    "    print('=== Finish feature generation ===')\n",
    "    return trend_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = list()\n",
    "    # models.append(tm.ModelFunc.LOGISTIC_REG)\n",
    "\n",
    "    # models.append(tm.ModelFunc.LINEAR_REG)\n",
    "    # models.append(tm.ModelFunc.KNN_REG) \n",
    "    # models.append(tm.ModelFunc.DECISION_TREE_REG)\n",
    "    # models.append(tm.ModelFunc.RANDOM_FOREST_REG)\n",
    "    # models.append(tm.ModelFunc.CATBOOST_REG)\n",
    "    # models.append(tm.ModelFunc.XGBOOST_REG)\n",
    "\n",
    "    # models.append(tm.ModelFunc.XGBOOST_CLASS)\n",
    "    # models.append(tm.ModelFunc.CATBOOST_CLASS)\n",
    "\n",
    "    # models.append(tm.ModelFunc.RANDOM_FOREST_CLASS)\n",
    "    models.append(tm.ModelFunc.DECISION_TREE_CLASS)\n",
    "    models.append(tm.ModelFunc.KNN_CLASS)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing job scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'new_data_dir': 'crypto_data',\n",
    "    'data_store_dir': '_data_store',\n",
    "    'time_interval': '1d',\n",
    "    'period': -(datetime.now() - datetime(2019, 1, 1)).days,\n",
    "    'tickers': ['BTC-USD'],\n",
    "    # 'tickers': ['BTC-USD', 'ETH-USD', 'SOL-USD', 'XRP-USD'],\n",
    "\n",
    "    'lag_periods': 3, #7\n",
    "    'min_outliers': .23,\n",
    "    'max_outliers': .77,\n",
    "    'trend_indicators': [ 'emaf', 'emam', 'emas', 'rsi', 'macd', 'adx' ],\n",
    "    'target_columns': ['Target'],\n",
    "    'OHLCV': ['Open', 'High', 'Low', 'Close', 'Volume'],\n",
    "\n",
    "    # 'max_train_size': 120,\n",
    "    # 'test_size': 60,\n",
    "    'max_train_size': 90,\n",
    "    'test_size': 30,\n",
    "    # 'max_train_size': 180,\n",
    "    # 'test_size': 90,\n",
    "\n",
    "    'file_compress': True,\n",
    "    'use_stacking': True,\n",
    "    'use_blending': False,\n",
    "    'model_funcs': get_models(),\n",
    "    'train_func': train_model,\n",
    "    'is_train': True,\n",
    "    'is_plot': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_job(params):\n",
    "    new_data_dir = params['new_data_dir']\n",
    "    tickers = params['tickers']\n",
    "    period = params['period']\n",
    "    time_interval = params['time_interval']\n",
    "\n",
    "    print(f'=== Start job: {datetime.now()} ===')\n",
    "    \n",
    "    # Load new data\n",
    "    crypto_dir = load_data_at_start_date(tickers, period, time_interval, new_data_dir)\n",
    "    # crypto_dir = load_data_period(tickers, datetime(2019, 1, 1), datetime(2024, 12, 31), time_interval)\n",
    "\n",
    "    trend_features = feature_generation(params)\n",
    "\n",
    "    if params['is_train']:\n",
    "        params['trend_features'] = trend_features\n",
    "        train_model(params)\n",
    "    \n",
    "    print(f'=== Finish job: {datetime.now()} ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Start job: 2025-01-11 14:36:55.117992 ===\n",
      "Start load data, tickers ['BTC-USD'], interval: 1d, from: -2202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2203 entries, 2019-01-01 to 2025-01-11\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   (BTC-USD, Open)       2203 non-null   float64\n",
      " 1   (BTC-USD, High)       2203 non-null   float64\n",
      " 2   (BTC-USD, Low)        2203 non-null   float64\n",
      " 3   (BTC-USD, Close)      2203 non-null   float64\n",
      " 4   (BTC-USD, Adj Close)  2203 non-null   float64\n",
      " 5   (BTC-USD, Volume)     2203 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 120.5 KB\n",
      "Download data completed\n",
      "=== Start feature generation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Add feature, ticker: BTC-USD ===\n",
      "Outliers detected: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish feature generation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 2048\n",
      "=== Start Train models:\n",
      " [<function xgboost_classifier_model at 0x7f0731f5eb60>, <function catboot_classifier_model at 0x7f0731f5e660>, <function decision_tree_classifier_model at 0x7f0731f5e8e0>, <function knn_classifier_model at 0x7f0731f5ea20>] ===\n",
      "     Train size: 4095, Val size: 1755, Test size: 1950\n",
      "Pred Train size: 4095, Val size: 1755, Test size: 1950\n",
      "=== Train sample metrics ===\n",
      "ROC AUC: 1.0000\n",
      "   Cutoff   Precision      Recall   Accuracy    F1-Score\n",
      "0    50.0   99.953789  100.000000   99.97558   99.976889\n",
      "1    60.0  100.000000  100.000000  100.00000  100.000000\n",
      "2    70.0  100.000000  100.000000  100.00000  100.000000\n",
      "3    80.0  100.000000   99.907536   99.95116   99.953747\n",
      "=== Val sample metrics ===\n",
      "ROC AUC: 0.4863\n",
      "   Cutoff  Precision     Recall   Accuracy   F1-Score\n",
      "0    50.0  51.239669  53.621622  48.660969  52.403592\n",
      "1    60.0  50.991189  50.054054  48.319088  50.518276\n",
      "2    70.0  50.835322  46.054054  48.091168  48.326716\n",
      "3    80.0  50.913838  42.162162  48.091168  46.126552\n",
      "=== Test sample metrics ===\n",
      "ROC AUC: 0.4938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [32:22<00:00, 1942.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cutoff  Precision     Recall   Accuracy   F1-Score\n",
      "0    50.0  52.194211  54.061896  49.384615  53.111639\n",
      "1    60.0  52.234359  50.870406  49.282051  51.543361\n",
      "2    70.0  51.991389  46.711799  48.871795  49.210392\n",
      "3    80.0  51.847437  42.069632  48.564103  46.449546\n",
      "===========================\n",
      "=== Finish Train models ===\n",
      "=== Finish job: 2025-01-11 15:09:20.610264 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_job(params)\n",
    "\n",
    "# scheduler = BlockingScheduler(job_defaults={'misfire_grace_time': 15*60})\n",
    "# scheduler = BackgroundScheduler(job_defaults={'misfire_grace_time': 15*60})\n",
    "# # scheduler.add_job(start_job, 'cron', day_of_week='mon-fri', hour='*/4', minute=5, jitter=120, timezone=get_localzone())\n",
    "# scheduler.add_job(start_job, 'interval', seconds=15, args=[params])\n",
    "# scheduler.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.shutdown(wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
