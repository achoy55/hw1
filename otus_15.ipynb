{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfinance version: 0.2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 16:36:41.282680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736163401.317840    4298 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736163401.328160    4298 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 16:36:41.362981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import import_ipynb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import talib as ta\n",
    "\n",
    "from redis_cli import RedisClient\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from file_loader import get_data, store_to_file\n",
    "from features import FeatureEngineering\n",
    "from data_loader import load_crypto_data, load_crypto_data2\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = RedisClient(db=1, username='usr_redis', password='usr_pwd')\n",
    "# r.test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "period=-(datetime.now() - datetime(2019, 1, 1)).days\n",
    "# period=-(datetime(2024,12,27) - datetime(2019, 1, 1)).days\n",
    "time_interval='1d'\n",
    "tickers = ['BTC-USD', 'ETH-USD'] #, 'SOL-USD', 'XRP-USD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start load crypto data, tickers ['BTC-USD', 'ETH-USD'], interval: 1d, from: 2019-01-01 16:36:44.319608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2198 entries, 2019-01-01 to 2025-01-06\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   (ETH-USD, Open)       2198 non-null   float64\n",
      " 1   (ETH-USD, High)       2198 non-null   float64\n",
      " 2   (ETH-USD, Low)        2198 non-null   float64\n",
      " 3   (ETH-USD, Close)      2198 non-null   float64\n",
      " 4   (ETH-USD, Adj Close)  2198 non-null   float64\n",
      " 5   (ETH-USD, Volume)     2198 non-null   int64  \n",
      " 6   (BTC-USD, Open)       2198 non-null   float64\n",
      " 7   (BTC-USD, High)       2198 non-null   float64\n",
      " 8   (BTC-USD, Low)        2198 non-null   float64\n",
      " 9   (BTC-USD, Close)      2198 non-null   float64\n",
      " 10  (BTC-USD, Adj Close)  2198 non-null   float64\n",
      " 11  (BTC-USD, Volume)     2198 non-null   int64  \n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 223.2 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %run crypto_data_loader.ipynb\n",
    "crypto_dir = load_crypto_data(tickers, period, time_interval)\n",
    "# crypto_dir = load_crypto_data2(tickers, datetime(2019, 1, 1), datetime(2024, 12, 31), time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_and_plot(data, column_name1, column_name2):\n",
    "    df = data.copy()\n",
    "    X_train = df[column_name1]\n",
    "    y_train = df[column_name2]\n",
    "\n",
    "    # without normalization\n",
    "    model_no_norm = ut.linear_regression(X_train, y_train)\n",
    "    weights_no_norm = model_no_norm.coef_\n",
    "\n",
    "    # normalize data\n",
    "    prices_norm, volume_norm = ut.normalize_MinMax_by_column(X_train, y_train)\n",
    "    # print(prices_norm)\n",
    "\n",
    "    model_with_norm = ut.linear_regression(prices_norm, volume_norm)\n",
    "    weights_with_norm = model_with_norm.coef_\n",
    "\n",
    "    # Plotting the weights\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    axes[0].bar(['Price', 'Volume'], weights_no_norm, color='red')\n",
    "    axes[0].set_title('Weigth without normalization')\n",
    "    axes[0].set_ylabel('Model weghts')\n",
    "\n",
    "    axes[1].bar(['Price', 'Volume'], weights_with_norm, color='green')\n",
    "    axes[1].set_title('Weigth after normalization')\n",
    "    axes[1].set_ylabel('Model weghts')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_type = file, redis\n",
    "def merge_and_store_data(new_df, key, store_type='file', compress=False):\n",
    "    if store_type == 'redis':\n",
    "        saved_data = r.get_key(key)\n",
    "    else:\n",
    "        saved_data = get_data('_data_store', key, compress=compress)\n",
    "\n",
    "    merged_df = ut.validate_duplicate_and_merge(saved_data, new_df)\n",
    "\n",
    "    if store_type == 'redis':\n",
    "        r.set_key(key, merged_df)\n",
    "    else:\n",
    "        store_to_file(merged_df, key, compress=compress)\n",
    "\n",
    "    merged_df.dropna(inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, n_splits, X, y, date_col = None):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (11, 7))\n",
    "    \n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=10, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits))\n",
    "    \n",
    "    if date_col is not None:\n",
    "        tick_locations  = ax.get_xticks()\n",
    "        tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-1])].astype(str).tolist() + [\" \"]\n",
    "\n",
    "        tick_locations_str = [str(int(i)) for i in tick_locations]\n",
    "        new_labels = ['\\n\\n'.join(x) for x in zip(list(tick_locations_str), tick_dates) ]\n",
    "        ax.set_xticks(tick_locations)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    \n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+0.2, -.2])\n",
    "    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importance(model, model_func, params):\n",
    "    importance_function = model.coef_[0]\n",
    "    if model_func in [ut.ModelFunc.XGBOOST_CLASS, ut.ModelFunc.DECISION_TREE_CLASS, ut.ModelFunc.RANDOM_FOREST_CLASS, \\\n",
    "                      ut.ModelFunc.KNN_CLASS, ]:\n",
    "        importance_function = model.feature_importances_\n",
    "    if model_func in [ut.ModelFunc.CATBOOST_CLASS, ]:\n",
    "        importance_function = model.get_feature_importance()\n",
    "\n",
    "    ut.top_n_weighted_factors(importance_function, params['features'], params['top'])\n",
    "    return importance_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Blending, Stacking, Ensemble\n",
    "def fit_models(model_funcs, X_train, y_train, X_val=None, y_val=None):\n",
    "    models = list()\n",
    "    for model_func in model_funcs:\n",
    "        params = ut.get_model_params(model_func)\n",
    "        if X_val is None or y_val is None:\n",
    "            model = ut.model_fit(model_func, X_train, y_train, params)\n",
    "        else:\n",
    "            if model_func is ut.ModelFunc.CATBOOST_CLASS:\n",
    "                params = dict(params, early_stopping_rounds=50)\n",
    "                model = ut.model_fit_with_eval(model_func, X_train, y_train, eval_set=(X_val, y_val), params=params)\n",
    "            else:\n",
    "                model = ut.model_fit(model_func, X_train, y_train, params)\n",
    "        models.append(model)\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_models(models, X_train, X_val, X_test):\n",
    "    models_proba = list()\n",
    "    for model in models:\n",
    "        models_proba.append({\n",
    "            'train': np.array(model.predict_proba(X_train)[:, 1]),\n",
    "            'val': np.array(model.predict_proba(X_val)[:, 1]),\n",
    "            'test': np.array(model.predict_proba(X_test)[:, 1])\n",
    "        })\n",
    "\n",
    "    return models_proba\n",
    "\n",
    "\n",
    "def blending_pred(*args):\n",
    "    return sum(args) / len(args)\n",
    "    \n",
    "def stacking_pred(*args):\n",
    "    return np.column_stack(args)\n",
    "\n",
    "# stacking_pred(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_with_features, ):\n",
    "    test_start_date = pd.to_datetime(data_with_features.index.max()) - pd.DateOffset(months=1)\n",
    "    val_start_date = pd.to_datetime(data_with_features.index.max()) - pd.DateOffset(months=2)\n",
    "\n",
    "    train_data = data_with_features[pd.to_datetime(data_with_features.index) < val_start_date] \n",
    "    val_data = data_with_features[(pd.to_datetime(data_with_features.index) >= val_start_date) & \\\n",
    "                                  (pd.to_datetime(data_with_features.index) < test_start_date)]\n",
    "    test_data = data_with_features[pd.to_datetime(data_with_features.index) >= test_start_date]\n",
    "    # print(data_with_features.index[-1], train_data.index[-1], val_data.index[-1], test_data.index[-1])    \n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'emaf': 20,\n",
    "    'emam': 100,\n",
    "    'emas': 150,\n",
    "    'rsi': 14,\n",
    "    'macd': [12, 26, 9],\n",
    "    'max_train_size': 180,\n",
    "    'test_size': 60,\n",
    "    # 'max_train_size': 90,\n",
    "    # 'test_size': 30\n",
    "}\n",
    "\n",
    "trend_indicators = [ 'emaf', 'emam', 'emas', 'rsi', 'macd', 'adx']\n",
    "# trend_indicators = [ 'macd']\n",
    "lag_periods = 3 # depends on timeframe, 7 days - ???\n",
    "min_outliers=.23\n",
    "max_outliers=.77\n",
    "threshold = 0.6 # ???\n",
    "use_stacking = True\n",
    "use_blending = False\n",
    "\n",
    "fe = FeatureEngineering(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(model_funcs, data_with_features, features):\n",
    "    for train_data, val_data, test_data in tqdm(fe.split_data(data_with_features)):\n",
    "        X_train, y_train = train_data[features], train_data['Target']\n",
    "        X_val, y_val     = val_data[features], val_data['Target']\n",
    "        X_test, y_test   = test_data[features], test_data['Target']\n",
    "\n",
    "        ## Data normalization\n",
    "        X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_MinMaxScaler(X_train, X_val, X_test)\n",
    "        # X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_StandardScaler(X_train, X_val, X_test)\n",
    "    \n",
    "        ## Modeling\n",
    "        # models = models_fit(model_funcs, X_train_scaled, y_train, X_val=X_val, y_val=y_val)\n",
    "        models = fit_models(model_funcs, X_train_scaled, y_train)\n",
    "\n",
    "        ## Prediction on train, val and test samples\n",
    "        predict_dict = predict_models(models, X_train_scaled, X_val_scaled, X_test_scaled)\n",
    "\n",
    "        yield ( predict_dict, y_train, y_val, y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = list()\n",
    "    # models.append(ut.ModelFunc.LOGISTIC_REG)\n",
    "    # models.append(ut.ModelFunc.LINEAR_REG)\n",
    "    # models.append(ut.ModelFunc.KNN_REG)\n",
    "    models.append(ut.ModelFunc.DECISION_TREE_REG)\n",
    "    models.append(ut.ModelFunc.RANDOM_FOREST_REG)\n",
    "    # models.append(ut.ModelFunc.CATBOOST_REG)\n",
    "    # models.append(ut.ModelFunc.XGBOOST_REG)\n",
    "\n",
    "    # models.append(ut.ModelFunc.XGBOOST_CLASS)\n",
    "    # models.append(ut.ModelFunc.CATBOOST_CLASS)\n",
    "\n",
    "    # models.append(ut.ModelFunc.RANDOM_FOREST_CLASS)\n",
    "    # models.append(ut.ModelFunc.DECISION_TREE_CLASS)\n",
    "    # models.append(ut.ModelFunc.KNN_CLASS)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols =['BTC-USD']\n",
    "for symbol in symbols:\n",
    "# for name in tqdm(tickers):\n",
    "    print(f'=== symbol: {symbol}, stacking: {use_stacking}, blending: {use_blending} ===')\n",
    "\n",
    "    data = get_data(crypto_dir, symbol)\n",
    "    data.drop(columns=['chg', 'vol_chg'], inplace=True) # Could it be as features ?\n",
    "\n",
    "    df = fe.clear_invalid_targets(fe.add_target(fe.enrich_with_indicators(data), lag_periods))\n",
    "    # df = fe.clear_invalid_targets(fe.add_target2(fe.enrich_with_indicators(data)))\n",
    "    df = fe.validate_outliers(df, 'Close', min_outliers, max_outliers)\n",
    "    # # print(df.isnull().sum())\n",
    "    \n",
    "    ## Store data\n",
    "    # df = merge_and_store_data(df, symbol, compress=True) # Store data\n",
    "    # print(df.isnull().sum())\n",
    "\n",
    "    ## Add features\n",
    "    OHLCV = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    # Trend features\n",
    "    data_with_trend, new_trend_features = fe.create_trend_features(df, OHLCV, lag_periods)\n",
    "    # print(data_with_trend.isnull().sum())\n",
    "    features = new_trend_features + trend_indicators\n",
    "    data_with_features = data_with_trend[features + ['Target', 'Date']]\n",
    "\n",
    "    # Rolling features\n",
    "    # window_sizes = [7, 14, 30]\n",
    "    # data_with_rolling, new_rolling_features = fe.create_rolling_features(df, OHLCV, window_sizes)\n",
    "    # features = new_rolling_features + trend_indicators + ['Target']\n",
    "    # data_with_features = data_with_rolling[features + ['Date']]\n",
    "\n",
    "    # print(len(data_with_features))\n",
    "    # print(data_with_features.isnull().sum())\n",
    "    data_with_features.set_index('Date', inplace=True)\n",
    "    # display(data_with_features.tail(10))\n",
    "\n",
    "    train_data, val_data, test_data = split_data(data_with_features)\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data['Target']\n",
    "\n",
    "    X_val = val_data[features]\n",
    "    y_val = val_data['Target']\n",
    "\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data['Target']\n",
    "\n",
    "    print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    model_funcs = get_models()\n",
    "    print(f'Models: {model_funcs}')\n",
    "\n",
    "    ## Data normalization\n",
    "    X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_MinMaxScaler(X_train, X_val, X_test)\n",
    "    # X_train_scaled, X_val_scaled, X_test_scaled = ut.normalize_StandardScaler(X_train, X_val, X_test)\n",
    "\n",
    "    ## Modeling\n",
    "    # models = models_fit(model_funcs, X_train_scaled, y_train, X_val=X_val, y_val=y_val)\n",
    "    models = fit_models(model_funcs, X_train_scaled, y_train)\n",
    "\n",
    "    ## Prediction on train, val and test samples\n",
    "    predict_dict = predict_models(models, X_train_scaled, X_val_scaled, X_test_scaled)\n",
    "\n",
    "    stacked_train_X = stacking_pred([d['train'] for d in predict_dict][0])\n",
    "    stacked_val_X = stacking_pred([d['val'] for d in predict_dict][0])\n",
    "    stacked_test_X = stacking_pred([d['test'] for d in predict_dict][0])\n",
    "    \n",
    "    final_model_func = ut.ModelFunc.LOGISTIC_REG \n",
    "    final_model = fit_models([final_model_func], stacked_train_X, y_train)[0]\n",
    "    predict_dict = predict_models([final_model], stacked_train_X, stacked_val_X, stacked_test_X)\n",
    "\n",
    "    ensemble_train = [d['train'] for d in predict_dict][0]\n",
    "    ensemble_val = [d['val'] for d in predict_dict][0]\n",
    "    ensemble_test = [d['test'] for d in predict_dict][0]\n",
    "\n",
    "    # ## Display metrics, ROC AUC for train, val and test samples\n",
    "    train_roc_auc = ut.roc_auc_score_metric(y_train, ensemble_train)\n",
    "    val_roc_auc = ut.roc_auc_score_metric(y_val, ensemble_val)\n",
    "    test_roc_auc = ut.roc_auc_score_metric(y_test, ensemble_test)\n",
    "  \n",
    "    print('=== Train sample metrics ===')\n",
    "    print(f'ROC AUC: {train_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_train, ensemble_train))\n",
    "\n",
    "    print('=== Val sample metrics ===')\n",
    "    print(f'ROC AUC: {val_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_val, ensemble_val))\n",
    "\n",
    "    print('=== Test sample metrics ===')\n",
    "    print(f'ROC AUC: {test_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_test, ensemble_test))\n",
    "    print('===========================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== symbol: BTC-USD, stacking: True, blending: False ===\n",
      "Outliers detected: 0\n",
      "Models: [<function decision_tree_regressor_model at 0x7fb44414de40>, <function random_forest_regressor_model at 0x7fb44414dd00>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeRegressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m y_val_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     48\u001b[0m y_test_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predict_dict, y_train, y_val, y_test \u001b[38;5;129;01min\u001b[39;00m predict_ensemble(model_funcs, data_with_features, features):\n\u001b[1;32m     51\u001b[0m     y_train_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_train_total, y_train], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m     y_val_total \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_val_total, y_val], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mpredict_ensemble\u001b[0;34m(model_funcs, data_with_features, features)\u001b[0m\n\u001b[1;32m     13\u001b[0m models \u001b[38;5;241m=\u001b[39m fit_models(model_funcs, X_train_scaled, y_train)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m## Prediction on train, val and test samples\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m predict_dict \u001b[38;5;241m=\u001b[39m predict_models(models, X_train_scaled, X_val_scaled, X_test_scaled)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m ( predict_dict, y_train, y_val, y_test )\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m, in \u001b[0;36mpredict_models\u001b[0;34m(models, X_train, X_val, X_test)\u001b[0m\n\u001b[1;32m     19\u001b[0m models_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     21\u001b[0m     models_proba\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(model\u001b[38;5;241m.\u001b[39mpredict_proba(X_train)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     25\u001b[0m     })\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models_proba\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeRegressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "symbols =['BTC-USD']\n",
    "for symbol in symbols:\n",
    "# for name in tqdm(tickers):\n",
    "    print(f'=== symbol: {symbol}, stacking: {use_stacking}, blending: {use_blending} ===')\n",
    "\n",
    "    data = get_data(crypto_dir, symbol)\n",
    "    data.drop(columns=['chg', 'vol_chg'], inplace=True) # Could it be as features ?\n",
    "\n",
    "    df = fe.clear_invalid_targets(fe.add_target(fe.enrich_with_indicators(data), lag_periods))\n",
    "    # df = fe.clear_invalid_targets(fe.add_target2(fe.enrich_with_indicators(data)))\n",
    "    df = fe.validate_outliers(df, 'Close', min_outliers, max_outliers)\n",
    "    # # print(df.isnull().sum())\n",
    "    \n",
    "    ## Store data\n",
    "    # df = merge_and_store_data(df, symbol, compress=True) # Store data\n",
    "    # print(df.isnull().sum())\n",
    "\n",
    "    ## Add features\n",
    "    OHLCV = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    # Trend features\n",
    "    data_with_trend, new_trend_features = fe.create_trend_features(df, OHLCV, lag_periods)\n",
    "    # print(data_with_trend.isnull().sum())\n",
    "    features = new_trend_features + trend_indicators\n",
    "    data_with_features = data_with_trend[features + ['Target', 'Date']]\n",
    "\n",
    "    # Rolling features\n",
    "    # window_sizes = [7, 14, 30]\n",
    "    # data_with_rolling, new_rolling_features = fe.create_rolling_features(df, OHLCV, window_sizes)\n",
    "    # features = new_rolling_features + trend_indicators\n",
    "    # data_with_features = data_with_rolling[features + ['Target', 'Date']]\n",
    "\n",
    "    # print(len(data_with_features))\n",
    "    # print(data_with_features.isnull().sum())\n",
    "    data_with_features.set_index('Date', inplace=True)\n",
    "    # display(data_with_features.tail(10))\n",
    "\n",
    "    ## Models\n",
    "    model_funcs = get_models()\n",
    "    print(f'Models: {model_funcs}')\n",
    "\n",
    "    ## Split, predict\n",
    "    y_train_pred_prob = list()\n",
    "    y_val_pred_prob = list()\n",
    "    y_test_pred_prob = list()\n",
    "    y_train_total = pd.DataFrame()\n",
    "    y_val_total = pd.DataFrame()\n",
    "    y_test_total = pd.DataFrame()\n",
    "\n",
    "    for predict_dict, y_train, y_val, y_test in predict_ensemble(model_funcs, data_with_features, features):\n",
    "        y_train_total = pd.concat([y_train_total, y_train], ignore_index=True)\n",
    "        y_val_total = pd.concat([y_val_total, y_val], ignore_index=True)\n",
    "        y_test_total = pd.concat([y_test_total, y_test], ignore_index=True)\n",
    "\n",
    "        y_train_pred_prob.append([d['train'] for d in predict_dict][0])\n",
    "        y_val_pred_prob.append([d['val'] for d in predict_dict][0])\n",
    "        y_test_pred_prob.append([d['test'] for d in predict_dict][0])\n",
    "\n",
    "    ## 2D-array\n",
    "    train_pred_prob = hstack(y_train_pred_prob)\n",
    "    val_pred_prob = hstack(y_val_pred_prob)\n",
    "    test_pred_prob = hstack(y_test_pred_prob)\n",
    "\n",
    "    print(f\"     Train size: {len(y_train_total)}, Val size: {len(y_val_total)},   Test size: {len(y_test_total)}\")\n",
    "    print(f\"Pred Train size: {len(train_pred_prob)}, Val size: {len(val_pred_prob)}, Test size: {len(test_pred_prob)}\")\n",
    "\n",
    "    ## Final model using whole data\n",
    "    if use_stacking:\n",
    "        stacked_train_X = stacking_pred(train_pred_prob).reshape(-1,1)\n",
    "        stacked_val_X = stacking_pred(val_pred_prob).reshape(-1,1)\n",
    "        stacked_test_X = stacking_pred(test_pred_prob).reshape(-1,1)\n",
    "        \n",
    "        final_model_func = ut.ModelFunc.LOGISTIC_REG \n",
    "        final_model = fit_models([final_model_func], stacked_train_X, y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], stacked_train_X, stacked_val_X, stacked_test_X)\n",
    "\n",
    "    elif use_blending:\n",
    "        blended_train_X = stacking_pred(train_pred_prob).reshape(-1,1)\n",
    "        blended_val_X = stacking_pred(val_pred_prob).reshape(-1,1)\n",
    "        blended_test_X = stacking_pred(test_pred_prob).reshape(-1,1)\n",
    "\n",
    "        final_model_func = ut.ModelFunc.LOGISTIC_REG\n",
    "        final_model = fit_models([final_model_func], blended_train_X, y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], blended_train_X, blended_val_X, blended_test_X)\n",
    "\n",
    "    else:\n",
    "        final_model_func = model_funcs[0]\n",
    "        final_model = fit_models([final_model_func], train_pred_prob.reshape(-1,1), y_train_total)[0]\n",
    "        predict_dict = predict_models([final_model], train_pred_prob.reshape(-1,1), val_pred_prob.reshape(-1,1),\\\n",
    "                                       test_pred_prob.reshape(-1,1))\n",
    "\n",
    "    ensemble_train = [d['train'] for d in predict_dict][0]\n",
    "    ensemble_val = [d['val'] for d in predict_dict][0]\n",
    "    ensemble_test = [d['test'] for d in predict_dict][0]\n",
    "\n",
    "    # ## Display metrics, ROC AUC for train, val and test samples\n",
    "    train_roc_auc = ut.roc_auc_score_metric(y_train_total, ensemble_train)\n",
    "    val_roc_auc = ut.roc_auc_score_metric(y_val_total, ensemble_val)\n",
    "    test_roc_auc = ut.roc_auc_score_metric(y_test_total, ensemble_test)\n",
    "  \n",
    "    print('=== Train sample metrics ===')\n",
    "    print(f'ROC AUC: {train_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_train_total, ensemble_train))\n",
    "\n",
    "    print('=== Val sample metrics ===')\n",
    "    print(f'ROC AUC: {val_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_val_total, ensemble_val))\n",
    "\n",
    "    print('=== Test sample metrics ===')\n",
    "    print(f'ROC AUC: {test_roc_auc:.4f}')\n",
    "    print(ut.calculate_metrics_table(y_test_total, ensemble_test))\n",
    "    print('===========================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
